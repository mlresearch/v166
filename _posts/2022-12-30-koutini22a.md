---
title: Learning General Audio Representations With Large-Scale Training of Patchout
  Audio Transformers
abstract: The success of supervised deep learning methods is largely due to their
  ability to learn relevant features from raw data. Deep Neural Networks (DNNs) trained
  on large-scale datasets are capable of capturing a diverse set of features, and
  learning a representation that can generalize onto unseen tasks and datasets that
  are from the same domain. Hence, these models can be used as powerful feature extractors,
  in combination with shallower models as classifiers, for smaller tasks and datasets
  where the amount of training data is insufficient for learning an end-to-end model
  from scratch. During the past years, Convolutional Neural Networks (CNNs) have largely
  been the method of choice for audio processing. However, recently attention-based
  transformer models have demonstrated great potential in supervised settings, outperforming
  CNNs. In this work, we investigate the use of audio transformers trained on large-scale
  datasets to learn general-purpose representations. We study how the different setups
  in these audio transformers affect the quality of their embeddings. We experiment
  with the models’ time resolution, extracted embedding level, and receptive fields
  in order to see how they affect performance on a variety of tasks and datasets,
  following the HEAR 2021 NeurIPS challenge evaluation setup. Our results show that
  representations extracted by audio transformers outperform CNN representations.
  Furthermore, we will show that transformers trained on Audioset can be extremely
  effective representation extractors for a wide range of downstream tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: koutini22a
month: 0
tex_title: Learning General Audio Representations With Large-Scale Training of Patchout
  Audio Transformers
firstpage: 65
lastpage: 89
page: 65-89
order: 65
cycles: false
bibtex_author: Koutini, Khaled and Masoudian, Shahed and Schmid, Florian and Eghbal-zadeh,
  Hamid and Schl\"{u}ter, Jan and Widmer, Gerhard
author:
- given: Khaled
  family: Koutini
- given: Shahed
  family: Masoudian
- given: Florian
  family: Schmid
- given: Hamid
  family: Eghbal-zadeh
- given: Jan
  family: Schlüter
- given: Gerhard
  family: Widmer
date: 2022-12-30
address:
container-title: 'HEAR: Holistic Evaluation of Audio Representations (NeurIPS 2021
  Competition)'
volume: '166'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 12
  - 30
pdf: https://proceedings.mlr.press/v166/koutini22a/koutini22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
