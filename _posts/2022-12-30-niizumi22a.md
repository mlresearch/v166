---
title: Masked Spectrogram Modeling using Masked Autoencoders for Learning General-purpose
  Audio Representation
abstract: " Recent general-purpose audio representations show state-of-the-art performance
  on various audio tasks. These representations are pre-trained by self-supervised
  learning methods that create training signals from the input. For example, typical
  audio contrastive learning uses temporal relationships among input sounds to create
  training signals, whereas some methods use a difference among input views created
  by data augmentations. However, these training signals do not provide information
  derived from the intact input sound, which we think is suboptimal for learning representation
  that describes the input as it is. In this paper, we seek to learn audio representations
  from the input itself as supervision using a pretext task of auto-encoding of masked
  spectrogram patches, Masked Spectrogram Modeling (MSM, a variant of Masked Image
  Modeling applied to audio spectrogram). To implement MSM, we use Masked Autoencoders
  (MAE), an image self-supervised learning method. MAE learns to efficiently encode
  the small number of visible patches into latent representations to carry essential
  information for reconstructing a large number of masked patches. While training,
  MAE minimizes the reconstruction error, which uses the input as training signal,
  consequently achieving our goal. We conducted experiments on our MSM using MAE (MSM-MAE)
  models under the evaluation benchmark of the HEAR 2021 NeurIPS Challenge. Our MSM-MAE
  models outperformed the HEAR 2021 Challenge results on seven out of 15 tasks (e.g.,
  accuracies of 73.4% on CREMA-D and 85.8% on LibriCount), while showing top performance
  on other tasks where specialized models perform better. We also investigate how
  the design choices of MSM-MAE impact the performance and conduct qualitative analysis
  of visualization outcomes to gain an understanding of learned representations. We
  have made our code available online for further improvements and applications of
  the MSM framework. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: niizumi22a
month: 0
tex_title: Masked Spectrogram Modeling using Masked Autoencoders for Learning General-purpose
  Audio Representation
firstpage: 1
lastpage: 24
page: 1-24
order: 1
cycles: false
bibtex_author: Niizumi, Daisuke and Takeuchi, Daiki and Ohishi, Yasunori and Harada,
  Noboru and Kashino, Kunio
author:
- given: Daisuke
  family: Niizumi
- given: Daiki
  family: Takeuchi
- given: Yasunori
  family: Ohishi
- given: Noboru
  family: Harada
- given: Kunio
  family: Kashino
date: 2022-12-30
address:
container-title: 'HEAR: Holistic Evaluation of Audio Representations (NeurIPS 2021
  Competition)'
volume: '166'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 12
  - 30
pdf: https://proceedings.mlr.press/v166/niizumi22a/niizumi22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
